{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4I_W4WjBKK9"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.32.0 peft==0.5.0\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate\n",
        "!pip install torch\n",
        "!pip install peft\n",
        "!pip install datasets\n",
        "!pip install bitsandbytes\n",
        "#!pip install bitsandbytes --prefer-binary --extra-index-url=https://jllllll.github.io/bitsandbytes-windows-webui\n",
        "!pip install accelerate\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JaxucTSuBfUC"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM, LlamaTokenizerFast\n",
        "from peft import PeftModel  # 0.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yavutKtBBsDa"
      },
      "outputs": [],
      "source": [
        "base_model = \"NousResearch/Llama-2-13b-hf\"\n",
        "peft_model = \"FinGPT/fingpt-sentiment_llama2-13b_lora\"\n",
        "tokenizer = LlamaTokenizerFast.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = LlamaForCausalLM.from_pretrained(base_model, trust_remote_code=True, device_map = \"cuda:0\", load_in_8bit = True,)\n",
        "model = PeftModel.from_pretrained(model, peft_model)\n",
        "model = model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = [\n",
        "'''Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}\n",
        "Input: FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is aggressively pursuing its growth strategy by increasingly focusing on technologically more demanding HDI printed circuit boards PCBs .\n",
        "Answer: ''',\n",
        "'''Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}\n",
        "Input: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\n",
        "Answer: ''',\n",
        "'''Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}\n",
        "Input: A tinyurl link takes users to a scamming site promising that users can earn thousands of dollars by becoming a Google ( NASDAQ : GOOG ) Cash advertiser .\n",
        "Answer: ''',\n",
        "]\n"
      ],
      "metadata": {
        "id": "x56uBQ7NIcfi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokens = tokenizer(prompt, return_tensors='pt', padding=True)\n",
        "#res = model.generate(**tokens, max_length=512)\n",
        "#res_sentences = [tokenizer.decode(i) for i in res]\n",
        "#out_text = [o.split(\"Answer: \")[1] for o in res_sentences]"
      ],
      "metadata": {
        "id": "b5M03WIdIe4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentiment in out_text:\n",
        "   print(sentiment)"
      ],
      "metadata": {
        "id": "8WUJZloOImAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import list_datasets, load_dataset\n",
        "dataset = load_dataset('zeroshot/twitter-financial-news-sentiment', split='validation[:2%]')"
      ],
      "metadata": {
        "id": "poXBMbX6JzJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_raw = dataset['text'][0:5]"
      ],
      "metadata": {
        "id": "Cp9cPEZQK9Wd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = []\n",
        "for i in prompt_raw:\n",
        "  prompt2_i = '''Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive} \\n Input: ''' + i + '''\\n Answer: '''\n",
        "  prompt2.append(prompt2_i)"
      ],
      "metadata": {
        "id": "wv-sH4WfVHf3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens2 = tokenizer(prompt2, return_tensors='pt', padding=True, max_length=512)\n",
        "res2 = model.generate(**tokens2,  max_length=512)\n",
        "res_sentences2 = [tokenizer.decode(i) for i in res2]\n",
        "out_text2 = [o.split(\"Answer: \")[1] for o in res_sentences2]"
      ],
      "metadata": {
        "id": "MgnZJRb-K2J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentiment in out_text2:\n",
        "   print(sentiment)"
      ],
      "metadata": {
        "id": "UV5lAKwjWXKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in prompt2:\n",
        "   print(p)"
      ],
      "metadata": {
        "id": "qXQ8zjpfWd-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def query(payload, model_id, api_token):\n",
        "\theaders = {\"Authorization\": f\"Bearer {api_token}\"}\n",
        "\tAPI_URL = f\"https://api-inference.huggingface.co/models/{model_id}\"\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "model_id = \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n",
        "#model_fin_id = \"FinGPT/fingpt-sentiment_llama2-13b_lora\"\n",
        "api_token = \"\" # get yours at hf.co/settings/tokens\n",
        "data = query(\"The goal of life is [MASK].\", model_id, api_token)"
      ],
      "metadata": {
        "id": "1hboKc3kbLRN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in prompt_raw:\n",
        "  q_p = query(p, model_id, api_token)\n",
        "  print(q_p)"
      ],
      "metadata": {
        "id": "MANU09jOcjC3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}